###############################################################
# import python libraries
###############################################################
import matplotlib.pyplot as plt
from wordcloud import WordCloud,ImageColorGenerator
from PIL import Image
import numpy as np
import streamlit as st
import pandas as pd
from annotated_text import annotated_text
import re
import ast
###############################################################
# page info 
###############################################################

st.set_page_config(
    page_title="Text Analysis -  HUMA5630-Digital Humanities - project-2024-group-3",
    page_icon="ğŸ“–", 
    layout="wide",
    initial_sidebar_state="expanded", 
)
st.caption("HUMA5630 Digital Humanities - Group 3")
###############################################################
# Background Image
###############################################################
# è®¾ç½®é¡µé¢èƒŒæ™¯å›¾å±‚
st.markdown(
    """
    <style>
    .header-container {
        background-image: url(https://img95.699pic.com/photo/40195/1356.jpg_wh300.jpg);
        background-size: cover;
        background-repeat: no-repeat;
        padding: 20px;
        color: white;
        text-align: center;
    }
    .header-container h1 {
        font-size: 40px;
        color: white;
        margin-bottom: 10px;
    }
    .header-container p {
        font-size: 20px;
        color: white;
        text-align: center;
        display: inline-block;
    }

    div[data-testid="stMarkdownContainer"] p {
        font-size: 20px;
        line-height: 2;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# æ˜¾ç¤ºæ ‡é¢˜æ–‡å­—å’Œå‰¯æ ‡é¢˜
st.markdown('<div class="header-container"><h1>About This Text</h1>', unsafe_allow_html=True)
###############################################################
# page content
###############################################################

st.markdown("")
st.markdown("The 'Classic of Mountains and Seas' is a renowned ancient Chinese text that delves into the rich tapestry of mythical geography, creatures, and cultures. Compiled over centuries, it stands as a testament to the profound imagination and curiosity of ancient Chinese scholars. Within its pages lie a mesmerizing blend of folklore, cosmology, and geography, offering readers a window into the imaginative worldviews of ancient China.")
st.markdown("The book has more than 38,000 words in total and is divided into eighteen sections; it describes over 550 mountains and 300 channels.")
st.markdown("---")

###############################################################
# Data --WordCloud
###############################################################
word_frequencies = {
    'æ›°': 551,
    'åæ›°': 309,
    'æ±': 211,
    'ä¹‹å±±': 183,
    'æµæ³¨': 179,
    'å…¶ç‹€': 174,
    'å±±': 125,
    'è¥¿': 115,
    'é³¥': 109,
    'ç¸': 104,
    'è‰æœ¨': 101,
    'äº': 92,
    'åŒ—': 92,
    'æ°´å‡º': 90,
    'å—': 84,
    'é»ƒ': 81,
    'ä¸‰ç™¾é‡Œ': 74,
    'äººé¢': 74,
    'æ°´': 64,
    'å…¶ä¸‹': 64,
    'å…¶é™½': 63,
    'æ³¨äº': 62,
    'æ±å—': 61,
    'åŒ—æµ': 59,
    'é£Ÿ': 58,
    'å…¶ä¸Š': 58,
    'çš†': 55,
    'äºŒç™¾é‡Œ': 51,
    'ç©€': 50,
    'å…¶æœ¨å¤š': 50,
    'å…¶éŸ³': 49,
    'å‡º': 44,
    'ç‹€': 43,
    'è›‡': 41,
    'é‡‘ç‰': 39,
    'é‡Œ': 39,
    'è‰': 39,
    'å¤§è’': 39,
    'é‡‘ç‰å…¶': 38,
    'äº”ç™¾é‡Œ': 37,
    'è¥¿å—': 36,
    'ä¹‹åœ‹': 36,
    'è‡³äº': 35,
    'äºŒåé‡Œ': 35,
    'æœ‰äºº': 35,
    'ç‰': 34,
    'è¥¿åŒ—': 34,
    'ä¹‹ä¸­': 34,
    'æœ¨': 32,
    'èµ¤': 32,
    'ä¹‹é¦–': 32,
    'äºæ²³': 31,
    'æœ‰å±±': 31,
    'è¦‹å‰‡': 30,
    'å‡ºäº': 30,
    'ä¸‰ç™¾': 29,
    'äº”åé‡Œ': 29,
    'å‡ºç„‰': 28,
    'å…¶ç¸': 28,
    'å°¾': 27,
    'çˆ°': 27,
    'ä¸ƒåé‡Œ': 26,
    'æ»': 26,
    'å…¶ç¥ ': 26,
    'é™°å¤š': 25,
    'å¤šç‰': 25,
    'ç™½': 24,
    'æ±åŒ—': 24,
    'å››ç™¾é‡Œ': 23,
    'ç˜': 23,
    'å¤©ä¸‹': 23,
    'å–™': 23,
    'å½˜': 22,
    'é¦–': 22,
    'ä¸‰åé‡Œ': 22,
    'ä¹‹æ°´å‡º': 22,
    'è‡º': 22,
    'æµæ²™': 22,
    'é•·': 21,
    'å±±ä¸Š': 21,
    'å´‘': 21,
    'å´™': 21,
    'ç‰›': 20,
    'èµ¤æ°´': 20,
    'ä¸‹å¤š': 20,
    'å…¶é³´': 20,
    'å…¶è‰': 20,
    'å±…': 20,
    'æµ·': 19,
    'ç³ˆ': 19,
    'çˆ': 19,
    'åœ‹': 19,
    'ç™½ç‰': 18,
    'ä¸‰ç™¾äº”åé‡Œ': 18,
    'æ®º': 18,
    'æ¯›': 18,
    'èº«': 17,
    'æœ‰ç¥': 17,
    'ç”Ÿ': 17,
    'å…¶æ±': 17
}



# åŠ è½½äº‘æœµå½¢çŠ¶çš„å›¾ç‰‡
cloud_mask = np.array(Image.open('./images/shanfeng.png'))

# åˆ›å»ºè¯äº‘å¯¹è±¡å¹¶é…ç½®ç›¸å…³å‚æ•°
wordcloud = WordCloud(font_path='./data/NotoSansTCBlack.ttf', background_color='white', mask=cloud_mask)

# ç”Ÿæˆè¯äº‘å›¾
wordcloud.generate_from_frequencies(word_frequencies)

# æ ¹æ®å›¾ç‰‡é¢œè‰²ç”Ÿæˆè¯äº‘å›¾çš„é¢œè‰²
image_colors = ImageColorGenerator(cloud_mask)
wordcloud.recolor(color_func=image_colors)

# æ˜¾ç¤ºè¯äº‘å›¾
st.title("Word Cloud")
st.markdown("As a geographical chronicle, there are many high-frequency words which are descriptive, such as \"name as\", as well as east, south, and west which describe geographical directions.")
fig, ax = plt.subplots(figsize=(80, 50), dpi=300)  # Adjust figsize and dpi for clarity
ax.imshow(wordcloud, interpolation='bilinear')
ax.axis('off')
st.pyplot(fig)
st.markdown("---")
##############################################################
##############################################################
# Data --TextCategory

st.title("Annotation on full text")

st.markdown(""" Annotation color: 
            <span style='background-color:#90b2ca;padding:5px 10px; border-radius:8px;'>Character</span>
            <span style='background-color:#e3bece;padding:5px 10px; border-radius:8px;'>Monster</span>
            <span style='background-color:#ead46f;padding:5px 10px; border-radius:8px;'>Treasure</span>
            <span style='background-color:#b2d9cb;padding:5px 10px; border-radius:8px;'>Location</span>
            """, unsafe_allow_html=True)


def highlight_name(text, cList, monsterList, tList, placeList):
    for word in cList:
        regex = re.compile(word)
        text = regex.sub('",("' + word + '", "Character", "#90b2ca"),"', text)
    for word in monsterList:
        regex = re.compile(word)
        text= regex.sub('",("' + word + '", "Monster", "#e3bece"),"', text)
    for word in tList:
        regex = re.compile(word)
        text= regex.sub('",("' + word + '", "Treasure", "#ead46f"),"', text)
    for word in placeList:
        regex = re.compile(word)
        text = regex.sub('",("' + word + '", "Location", "#b2d9cb"),"', text)
    return text


filepath = './data/shanhaijing.xlsx'
df = pd.read_excel(filepath, sheet_name='Sheet1')


cList = [name.strip() for name in df['Character'].astype(str).str.split('ã€').explode() if isinstance(name, str) and name.strip() and name.strip() != "nan" and len(name.strip()) > 1]
cList = list(set(cList)) #remove duplicates within the list
cList.sort(key=lambda x: len(x))
if "ç¦ºå½Š" in cList:
    cList.remove("ç¦ºå½Š") # remove to avoid conflict, monster list also have ç¦ºå½Š
if "é¡“é Š" in cList:
    cList.remove("é¡“é Š") # remove to avoid conflict with å¸é¡“é Š
if "èµ¤æ°´å¥³å­ç»" in cList:
    cList.remove("èµ¤æ°´å¥³å­ç»") # remove to avoid conflict with the location èµ¤æ°´
# check---- st.markdown(cList)

mList = [name.strip() for name in df['Monster'].astype(str).str.split('ã€').explode() if isinstance(name, str) and name.strip() and name.strip() != "nan"]
mList = list(set(mList)) #remove duplicates within the list
mList.sort(key=lambda x: len(x))

tList = [name.strip() for name in df['Treasure'].astype(str).str.split('ã€').explode() if isinstance(name, str) and name.strip() and name.strip() != "nan"]
tList = list(set(tList)) #remove duplicates within the list
tList.sort(key=lambda x: len(x))

placeList = [name.strip() for name in df['Location'].astype(str).str.split('ã€').explode() if isinstance(name, str) and name.strip() and name.strip() != "nan" and len(name.strip()) > 1]
placeList = list(set(placeList)) #remove duplicates within the list
placeList.sort(key=lambda x: len(x))
if "é¡“é Š" in placeList:
    placeList.remove("é¡“é Š") # remove to avoid conflict with å¸é¡“é Š



tab_hill, tab_sea = st.tabs(["å±±ç¶“", "æµ·ç»"])

with tab_hill:
    tab_names = df.loc[df["åˆ†é¡"] == "å±±ç¶“", "å·å®—"].unique().tolist()
    # Create tabs based on the unique values
    tabs = st.tabs(tab_names)
    # Display the content of each tab
    for i, tab in enumerate(tabs):
        with tab:
            fulltext = df.loc[df["å·å®—"] == tab_names[i], "æ–‡æœ¬"].values[0]
            fulltext = fulltext.replace("\n", "")
            # annotate    
            highlighted_text = '"' + highlight_name(fulltext, cList, mList, tList, placeList) + '"'
            highlighted_text = ast.literal_eval(highlighted_text) # Convert string to a list
            annotated_text(*highlighted_text)



with tab_sea:
    tab_names = df.loc[df["åˆ†é¡"] == "æµ·ç»", "å·å®—"].unique().tolist()
    # Create tabs based on the unique values
    tabs = st.tabs(tab_names)
    # Display the content of each tab
    for i, tab in enumerate(tabs):
        with tab:
            fulltext = df.loc[df["å·å®—"] == tab_names[i], "æ–‡æœ¬"].values[0]
            fulltext = fulltext.replace("\n", "")
            # annotate    
            highlighted_text = '"' + highlight_name(fulltext, cList, mList, tList, placeList) + '"'
            highlighted_text = ast.literal_eval(highlighted_text) # Convert string to a list
            annotated_text(*highlighted_text)
# æ’å…¥å›¾ç‰‡
image_path = "./images/shanhaitu.jpg"  # æ ¹æ®å®é™…æ–‡ä»¶è·¯å¾„è¿›è¡Œä¿®æ”¹
image = Image.open(image_path)
st.image(image, caption="", use_column_width=True)
st.markdown("<p style='font-size: 14px;'>æ’åœ–ï¼šã€Šå±±æµ·ç¶“ã€‹ä¸­çš„äººé­šï¼Œå¸¸è¢«æè¿°ä¸ºä¸ŠåŠèº«ä¸ºäººã€ä¸‹åŠèº«ä¸ºé±¼çš„å½¢è±¡ã€‚åœ¨ã€Šå±±ç¶“ã€‹ä¸­çš„ã€Šè¥¿å±±ç¶“ã€‹ã€ã€ŠåŒ—å±±ç¶“ã€‹ã€ã€Šä¸­å±±ç¶“ã€‹è£¡éƒ½æ›¾å‡ºç¾éäººé­šï¼Œåœ¨ä¸Šé¢çš„åŸæ–‡ä¸­å¯ä»¥æ‰¾åˆ°ã€‚</p>", unsafe_allow_html=True)
# å…¶ä»–å†…å®¹
###############################################################
# import python libraries
###############################################################

# åœ¨åº•éƒ¨åŠ ä¸Šåƒè€ƒè³‡æ–™
st.markdown("<h2 style='color: black;'>References:</h2>", unsafe_allow_html=True)
st.markdown("<p style='color: black;'>ã€Šå±±æµ·ç¶“ã€‹ï¼ˆæˆ°åœ‹è‡³æ¼¢ä»£ï¼Œå…¬å…ƒå‰475å¹´-220å¹´ï¼‰ï¼Œå–è‡ªhttps://ctext.org/shan-hai-jing/zhs</p>", unsafe_allow_html=True)
st.markdown("<p style='color: black;'>ç‹ç´…æ——ï¼šã€Šå…¨æœ¬ç¹ªåœ–å±±æµ·ç¶“ï¸°æµ·å…§å¤–ä¹ç¶“ã€‹ï¼Œæ­¦æ¼¢å¤§å­¸å‡ºç‰ˆç¤¾ï¼Œ2011å¹´4æœˆç¬¬1ç‰ˆã€‚</p>", unsafe_allow_html=True)
st.markdown("<p style='color: black;'>ç¾…å…ƒï¼šã€Šå±±ç²¾æµ·æ€ªï¼šèŒç³»å±±æµ·ç¶“å®Œå…¨åœ–è­œã€‹ï¼Œäººæ°‘éƒµé›»å‡ºç‰ˆç¤¾ï¼Œ2018å¹´6æœˆç¬¬1ç‰ˆã€‚</p>", unsafe_allow_html=True)
st.markdown("<p style='color: black;'>åŠ‰å®—è¿ªï¼šã€Šå¤±è½çš„å¤©æ›¸ã€Œã€Šå±±æµ·ç¶“ã€‹èˆ‡å¤ä»£è¯å¤ä¸–ç•Œè§€ï¼ˆå¢è¨‚æœ¬ï¼‰ã€‹ï¼Œå•†å‹™å°æ›¸é¤¨ï¼Œ2016å¹´5æœˆç¬¬1ç‰ˆã€‚</p>", unsafe_allow_html=True)
